{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As per the original problem statement, this solution is designed to follow a QAI-style agentic architecture, where multiple intelligent agents collaborate to solve a complex task.\n",
        "\n",
        "However, due to execution constraints—specifically, the Groq (Krok) API not being supported or executable in the current environment without API dependencies—the system does not directly invoke the QAI runtime or external APIs.\n",
        "\n",
        "Instead, to demonstrate the same agentic behavior, reasoning flow, and task orchestration, the implementation uses a local Hugging Face instruction-tuned language model.\n",
        "\n",
        "This approach preserves:\n",
        "\n",
        "Agent-level separation of responsibilities\n",
        "\n",
        "Sequential reasoning and orchestration\n",
        "\n",
        "Decision-driven workflow\n",
        "\n",
        "QAI-style modular intelligence\n",
        "\n",
        "The change is only at the LLM execution layer."
      ],
      "metadata": {
        "id": "gwW70vJ-ZIi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers torch sentencepiece\n",
        "\n"
      ],
      "metadata": {
        "id": "u2hGN0xAZJCK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    max_length=512,\n",
        "    do_sample=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idWd1XazZRa-",
        "outputId": "9313e4f4-519e-4fa4-ea00-b8bbb26e1a52"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'ApertusForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'BltForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FlexOlmoForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GptOssForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HunYuanMoEV1ForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'LongcatFlashForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MinistralForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'Olmo3ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'Qwen3NextForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SeedOssForCausalLM', 'SmolLM3ForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'VaultGemmaForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Machine Learning\"\n",
        "expertise_level = \"Intermediate\"\n"
      ],
      "metadata": {
        "id": "YwwiK04sbfWm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent 1: Learning Material Agent\n",
        "def learning_material_agent(topic):\n",
        "    prompt = f\"\"\"\n",
        "    You are a learning material curator.\n",
        "    Create a structured list of learning resources for {topic}.\n",
        "    Include:\n",
        "    - Articles\n",
        "    - Videos\n",
        "    - Hands-on Exercises\n",
        "    \"\"\"\n",
        "    response = llm(prompt)[0][\"generated_text\"]\n",
        "    return response\n",
        "\n"
      ],
      "metadata": {
        "id": "V5Lh4WKtZUHi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_output = learning_material_agent(topic)\n",
        "\n",
        "print(\"===== Learning Material Agent Output =====\\n\")\n",
        "print(learning_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJinvehbbmC4",
        "outputId": "da4a22c1-cfd0-4423-a087-591264f213be"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Learning Material Agent Output =====\n",
            "\n",
            "\n",
            "    You are a learning material curator.\n",
            "    Create a structured list of learning resources for Machine Learning.\n",
            "    Include:\n",
            "    - Articles\n",
            "    - Videos\n",
            "    - Hands-on Exercises\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent 2: Quiz Creation Agent\n",
        "def quiz_agent(topic, level):\n",
        "    prompt = f\"\"\"\n",
        "    You are a quiz creator.\n",
        "    Create a {level}-level quiz for the topic {topic}.\n",
        "    Generate 5 conceptual questions.\n",
        "    \"\"\"\n",
        "    response = llm(prompt)[0][\"generated_text\"]\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "Sgswo0xtbpw4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_output = quiz_agent(topic, expertise_level)\n",
        "\n",
        "print(\"\\n===== Quiz Creation Agent Output =====\\n\")\n",
        "print(quiz_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5y85W0rbtPI",
        "outputId": "1660bce8-7d5e-49c9-aed3-0511176fd319"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Quiz Creation Agent Output =====\n",
            "\n",
            "\n",
            "    You are a quiz creator.\n",
            "    Create a Intermediate-level quiz for the topic Machine Learning.\n",
            "    Generate 5 conceptual questions.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent 3: Project Recommendation Agent\n",
        "def project_agent(topic, level):\n",
        "    prompt = f\"\"\"\n",
        "    You are a project recommendation expert.\n",
        "    Suggest 3 practical projects for a learner with {level} experience in {topic}.\n",
        "    Each project should be industry-oriented.\n",
        "    \"\"\"\n",
        "    response = llm(prompt)[0][\"generated_text\"]\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "vL1PqvkqbvEC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_output = project_agent(topic, expertise_level)\n",
        "\n",
        "print(\"\\n===== Project Recommendation Agent Output =====\\n\")\n",
        "print(project_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcxnSNcLbyX-",
        "outputId": "6271e1be-e522-4db6-9825-790a78580892"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Project Recommendation Agent Output =====\n",
            "\n",
            "\n",
            "    You are a project recommendation expert.\n",
            "    Suggest 3 practical projects for a learner with Intermediate experience in Machine Learning.\n",
            "    Each project should be industry-oriented.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================ FINAL PERSONALIZED EDUCATION PLAN ================\\n\")\n",
        "\n",
        "print(\"Topic:\", topic)\n",
        "print(\"Expertise Level:\", expertise_level)\n",
        "\n",
        "print(\"\\n--- Learning Materials ---\\n\")\n",
        "print(learning_output)\n",
        "\n",
        "print(\"\\n--- Quiz ---\\n\")\n",
        "print(quiz_output)\n",
        "\n",
        "print(\"\\n--- Project Ideas ---\\n\")\n",
        "print(project_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOYem7e9b0sX",
        "outputId": "a703437b-7a44-4bfb-e6be-893e4d7d260d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ FINAL PERSONALIZED EDUCATION PLAN ================\n",
            "\n",
            "Topic: Machine Learning\n",
            "Expertise Level: Intermediate\n",
            "\n",
            "--- Learning Materials ---\n",
            "\n",
            "\n",
            "    You are a learning material curator.\n",
            "    Create a structured list of learning resources for Machine Learning.\n",
            "    Include:\n",
            "    - Articles\n",
            "    - Videos\n",
            "    - Hands-on Exercises\n",
            "    \n",
            "\n",
            "--- Quiz ---\n",
            "\n",
            "\n",
            "    You are a quiz creator.\n",
            "    Create a Intermediate-level quiz for the topic Machine Learning.\n",
            "    Generate 5 conceptual questions.\n",
            "    \n",
            "\n",
            "--- Project Ideas ---\n",
            "\n",
            "\n",
            "    You are a project recommendation expert.\n",
            "    Suggest 3 practical projects for a learner with Intermediate experience in Machine Learning.\n",
            "    Each project should be industry-oriented.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Telecom prepaid churn modeling\"\n",
        "expertise_level = \"Beginner\"\n",
        "\n",
        "# Pass this query to the system dynamically\n",
        "learning_output = learning_material_agent(user_query)\n",
        "quiz_output = quiz_agent(user_query, expertise_level)\n",
        "project_output = project_agent(user_query, expertise_level)\n"
      ],
      "metadata": {
        "id": "7kFAfTkwcq_N"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_personalized_plan(user_query, expertise_level):\n",
        "    # Agent 1\n",
        "    learning_output = learning_material_agent(user_query)\n",
        "\n",
        "    # Agent 2\n",
        "    quiz_output = quiz_agent(user_query, expertise_level)\n",
        "\n",
        "    # Agent 3\n",
        "    project_output = project_agent(user_query, expertise_level)\n",
        "\n",
        "    # Final aggregated output\n",
        "    print(\"\\n================ FINAL PERSONALIZED EDUCATION PLAN ================\\n\")\n",
        "    print(\"Topic / Query:\", user_query)\n",
        "    print(\"Expertise Level:\", expertise_level)\n",
        "\n",
        "    print(\"\\n--- Learning Materials ---\\n\")\n",
        "    print(learning_output)\n",
        "\n",
        "    print(\"\\n--- Quiz ---\\n\")\n",
        "    print(quiz_output)\n",
        "\n",
        "    print(\"\\n--- Project Ideas ---\\n\")\n",
        "    print(project_output)\n"
      ],
      "metadata": {
        "id": "hfJ8rZN8ctLJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_personalized_plan(\"Telecom prepaid churn modeling\", \"Intermediate\")\n",
        "run_personalized_plan(\"Deep Learning for NLP\", \"Beginner\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4OIqMV7czYF",
        "outputId": "57445965-1e1a-49e1-af1e-18c21332131c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ FINAL PERSONALIZED EDUCATION PLAN ================\n",
            "\n",
            "Topic / Query: Telecom prepaid churn modeling\n",
            "Expertise Level: Intermediate\n",
            "\n",
            "--- Learning Materials ---\n",
            "\n",
            "\n",
            "    You are a learning material curator.\n",
            "    Create a structured list of learning resources for Telecom prepaid churn modeling.\n",
            "    Include:\n",
            "    - Articles\n",
            "    - Videos\n",
            "    - Hands-on Exercises\n",
            "    \n",
            "\n",
            "--- Quiz ---\n",
            "\n",
            "\n",
            "    You are a quiz creator.\n",
            "    Create a Intermediate-level quiz for the topic Telecom prepaid churn modeling.\n",
            "    Generate 5 conceptual questions.\n",
            "    \n",
            "\n",
            "--- Project Ideas ---\n",
            "\n",
            "\n",
            "    You are a project recommendation expert.\n",
            "    Suggest 3 practical projects for a learner with Intermediate experience in Telecom prepaid churn modeling.\n",
            "    Each project should be industry-oriented.\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ FINAL PERSONALIZED EDUCATION PLAN ================\n",
            "\n",
            "Topic / Query: Deep Learning for NLP\n",
            "Expertise Level: Beginner\n",
            "\n",
            "--- Learning Materials ---\n",
            "\n",
            "\n",
            "    You are a learning material curator.\n",
            "    Create a structured list of learning resources for Deep Learning for NLP.\n",
            "    Include:\n",
            "    - Articles\n",
            "    - Videos\n",
            "    - Hands-on Exercises\n",
            "    \n",
            "\n",
            "--- Quiz ---\n",
            "\n",
            "\n",
            "    You are a quiz creator.\n",
            "    Create a Beginner-level quiz for the topic Deep Learning for NLP.\n",
            "    Generate 5 conceptual questions.\n",
            "    \n",
            "\n",
            "--- Project Ideas ---\n",
            "\n",
            "\n",
            "    You are a project recommendation expert.\n",
            "    Suggest 3 practical projects for a learner with Beginner experience in Deep Learning for NLP.\n",
            "    Each project should be industry-oriented.\n",
            "    ning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP - Deep Learning for NLP -\n"
          ]
        }
      ]
    }
  ]
}