{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSlL/yjmdam0Sufk07a4ux"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Code Debugging Assistant (CRU-AI)\n",
        "\n",
        "**Objective:**  \n",
        "This notebook demonstrates an agentic system that can automatically:\n",
        "1. Analyze Python code for syntax and logical errors\n",
        "2. Correct the identified issues\n",
        "3. Coordinate the workflow via a Manager agent\n",
        "\n",
        "**Agents involved:**\n",
        "- **Code Analyzer:** detects syntax/logical errors\n",
        "- **Code Corrector:** fixes the identified issues\n",
        "- **Manager:** oversees workflow execution\n",
        "\n",
        "**Note:**  \n",
        "We are not using OpenAI or Grok keys because they are either not available or not working as expected.  \n",
        "Instead, we simulate the behavior of an LLM locally using Python functions and LiteLLM for demonstration purposes.  \n",
        "This allows the notebook to run fully without any external API keys.\n"
      ],
      "metadata": {
        "id": "v89bUdHdQcId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers==0.20.3\n",
        "!pip install transformers accelerate sentencepiece --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwB4zJqqQcxa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658488984,
          "user_tz": -330,
          "elapsed": 53193,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "b1678853-a160-4128-b119-39437deef738"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers==0.20.3\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers==0.20.3) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2026.1.4)\n",
            "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.57.3 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.20.3\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "Successfully installed tokenizers-0.22.2 transformers-4.57.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYd4wQr7Qgoz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658536931,
          "user_tz": -330,
          "elapsed": 47938,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "e7c8dee8-0ef8-487f-e30e-8d7529a6844d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 3 \u2014 Initialize Hugging Face LLM Pipeline\n",
        "# Model: tiiuae/falcon-7b-instruct (free Hugging Face model)\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",   # Use GPU if available\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Create Hugging Face text generation pipeline\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=1024,\n",
        "    do_sample=True,\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print(\"Hugging Face LLM initialized successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513,
          "referenced_widgets": [
            "0b642684adb84a47970359294d187164",
            "e9ad02b4f86d4bd48ebdd0e72dd0b3d9",
            "6f0a824545ae4787ad12779b83234ad2",
            "34fc1fffb57c4212a530bdd898c99b24",
            "09a81bdb465e4974acfdbd3b49f9cd40",
            "e127ccfc0aa941429bbed6b234bbd2d4",
            "da8ee0faae054e6584afaeea4c5cfe0c",
            "82c13f07669e441788cc95501c2179b1",
            "bad02565613e49f2be994c8903488154",
            "27780296396c45c3adf2bb61348ec203",
            "c95e109c72504ac48df395d1293b4834",
            "940ceb0af5d54776a628b87320b32b68",
            "7c36daad3c174811ae31d89e1fd3fb88",
            "22f1a81edd6c466794ba4a5d67801596",
            "e51986e9ba1745c6a01286f5e113b19b",
            "194849fa0e514e5997a72a84c1fb3891",
            "ff42873517a040e89dfed497917d3f6a",
            "fcfa94b2f2464cb4baffc21c749d8847",
            "510920cd4a404cf3b25050632e34d227",
            "5f5bb71e8e114bf1aea7494c244314ff",
            "7cd09b42ee844030abcca005d3b99b5c",
            "51808e44e5054a09bc9fb3f278a907ac",
            "b5ec60c46b0842d99cb52ea54d8ffe51",
            "7d90a862d154491f95330a3d2ca6aafb",
            "950c53d214cd4d8588d380e53c30c15b",
            "d01698c98c644ba4a991766e38f073ee",
            "5ae3e3f882d349899f978897155cf1f7",
            "965e6a099d614ea5bc32c5744ed7f6bc",
            "855cc86f8a0941a79e9beff430c5dc6c",
            "a4796ae47a2946ecb00c16edfcd95b9e",
            "b8d2f148fe42453fa11070e7bdbcc8fe",
            "d652b285012440a8928d5773e95f8e5b",
            "7494429730ce4fc08ee4c4838470aaf4",
            "ebfb01e29d8d4971af61da2a7e3169f0",
            "ac023ca942344a11bd58544ff6abfd8b",
            "9fac3bfc21754be1b35abc5a33074926",
            "7cda5ca89d6049a2a18f59e4fd7e8aa9",
            "c658d239c3e147b19a4fada442e209b0",
            "627e3e3b7f2a46cea087c1d05d8a5116",
            "245612f15b9e4e0cb12258ee00899910",
            "685234b9674d404791398db4ab3d85d1",
            "17a02d1899ad4b479bb037b14a352809",
            "230dec571666479f9b05efdc90cc6782",
            "c7a928d0b9f842e7aa598fc6e1c29e44",
            "106e05a0e8314873b00d1e544e03b25d",
            "8d3df582d0754116a286b70443c632c8",
            "eb3957ecbd704f28b5ee3258e24e393e",
            "94c8a496140d42209ca7db29ed2d679d",
            "1d077c2a05194e38996d13015e3fce3a",
            "524ad1c1059a4a2685c6845c41de227c",
            "8af66142a79045b4b9c1268e269c1e0e",
            "723cf7cdd0df471ba44bcc4b37155248",
            "278e68d493b74cce9512d6f2d2f14f26",
            "13d6768c63a545708796ae31f334c302",
            "22ac77b8729a49d1b8bc5768320be8aa",
            "c73ea1fa378c45cf9929d8be6f81ba73",
            "53873e95af964f16a2839360f5cf065b",
            "a55f5e7f50444c46830d313d745cdfad",
            "be3848792aef48a7b2a1dd46514e8947",
            "b02b990625c947fa96b6d3e6e3ef60aa",
            "5e63c31017a24a22bc65f43dfa182759",
            "d42d39d8d962451cbda0c28c18881b0f",
            "762facb1b37e4405bd80c0e19529cbcb",
            "75543a3208314353b0fd7565558e225f",
            "de0c362081b14ce08106cd6d94f021d6",
            "2b7e0b9eb0284d0e9d36bcfd2b355c58",
            "2df3be65b8344c0d832aa4ce10de3b1e",
            "aafc625dd20d40ba971dbce46fad8686",
            "ec867c3ce0a84e0dbd58c296ad7582d0",
            "4ec714984d6b41b389f492ff6989cd9c",
            "b7f7ab9dee0b48c2b04b07bcf43f0a8c",
            "a55a2eaec7544043b267f4e8139766be",
            "78ea517f97524927ab31c6cf30707d1c",
            "8bb30bdbc0404728a103c716388a19e6",
            "63ff2fc1346b470897cd2b0c1b27dd34",
            "b96d3516d41a4c1798995d848e7b40f0",
            "fb8fd52fe9994ec5b2a31053ad1c309b",
            "4757c6c9b28f4bb08c3b6885db002e3c",
            "947eb7a88b0f47b790abbeba7d7167a5",
            "ccebe6ec85604cc69a31ffcc278df925",
            "240c9e42d19343a48fc7b3684c2ab43d",
            "88e8f33efa9e4db0b5672ed7dcd9399d",
            "5a2305f1079845b7aed61c9d5ebb2e90",
            "8abb6a4345564ebab0d57d527bc51525",
            "fb5f5b331d23486ab3b6554cbadb3bb9",
            "983f4bc9a3e9475491c635719f7ce7ed",
            "bee8d012d71847d4b79954e6380d6478",
            "3c6f263e5563411ab6f429877ca6f222",
            "39c5b20db3e94f289714f70b34420e15",
            "afd84fbd00db4ae4ab80ddf3873ea981",
            "7df26dba155c41258b0ec2e7593601ff",
            "a9efe7e16224457dad04d1094993794f",
            "fbd81a777b6c489cae5a6fea4fff949b",
            "99416e6249fc412fb752db0e15e06101",
            "c9fc82a9aad742339ed9af01c60f1a2b",
            "7731afa068ae4e55982826f0106674d1",
            "62032c91405d484bad6fe9812fea7f63",
            "9f3ea882cd8d4d2f8b473e055fcfc976",
            "5102946fefbd4ef69ca623ad72f9ab02",
            "4440339ec49f465d9073294a4c8bac9f",
            "6ed2ca8837414aa0a768f6af9e444d94",
            "9366b1d63022419090b3ac0c4dcfc036",
            "e890ab925a1f4f3ea6e45fba59f12a44",
            "102b8e76faf9479e968662ec58a3dc8c",
            "40b0278acb584f0c9f327783c603e800",
            "b74944da017049c690f57a2e713c1bd9",
            "5995d4c95fae4a738dd40f14e054948f",
            "4b1bfa31537f41078bbf48c9af681846",
            "160c51fa3fb347dbbd942293f15a4e49",
            "894b653328cc4fa4a82e8ebf8a06c332"
          ]
        },
        "id": "h5QuM4W0QgtT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658757605,
          "user_tz": -330,
          "elapsed": 220671,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "dc689c66-3b61-4c0e-fb3d-6fd087f3c4c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b642684adb84a47970359294d187164"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "940ceb0af5d54776a628b87320b32b68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5ec60c46b0842d99cb52ea54d8ffe51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebfb01e29d8d4971af61da2a7e3169f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106e05a0e8314873b00d1e544e03b25d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c73ea1fa378c45cf9929d8be6f81ba73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2df3be65b8344c0d832aa4ce10de3b1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4757c6c9b28f4bb08c3b6885db002e3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39c5b20db3e94f289714f70b34420e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4440339ec49f465d9073294a4c8bac9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face LLM initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 4 \u2014 Example Buggy Python Code\n",
        "buggy_code = \"\"\"\n",
        "def fibonacci(n):\n",
        "    if n < 0:\n",
        "        return []\n",
        "    elif n == 1:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 0, 1\n",
        "    else:\n",
        "        fib = [0, 1]\n",
        "        for i in range(2, n):\n",
        "            fib.append(fib[i-1] + fib[i-2])\n",
        "        return fib\n",
        "\"\"\"\n",
        "\n",
        "print(\"Buggy Python code loaded\")\n",
        "print(buggy_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_izK04MqQgv_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658757608,
          "user_tz": -330,
          "elapsed": 22,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "2d0fbd7d-d75f-4ef0-cd92-e9a3ae5ccd6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buggy Python code loaded\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 5 \u2014 Define Analyzer Agent\n",
        "def analyze_code(code):\n",
        "    prompt = f\"\"\"\n",
        "You are a Python code analyzer.\n",
        "Analyze the following Python code and list all syntax and logical errors clearly:\n",
        "\n",
        "{code}\n",
        "\"\"\"\n",
        "    result = llm(prompt)[0][\"generated_text\"]\n",
        "    return result\n",
        "\n",
        "# Test Analyzer\n",
        "analysis_report = analyze_code(buggy_code)\n",
        "print(\"=== Analysis Report ===\")\n",
        "print(analysis_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTHnfvKIQgzN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658784822,
          "user_tz": -330,
          "elapsed": 27213,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "07af945f-b40b-4643-fc4a-99a79e8ec6a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Analysis Report ===\n",
            "\n",
            "You are a Python code analyzer.\n",
            "Analyze the following Python code and list all syntax and logical errors clearly:\n",
            "\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "<p>Syntax errors:</p>\n",
            "\n",
            "<ul>\n",
            "<li>Incorrect syntax for the function name - <code>fibonacci</code> should be <code>fibonacci(n)</code></li>\n",
            "<li>Incorrect syntax for the function arguments - <code>n</code> should be a number (not a string)</li>\n",
            "<li>Incorrect syntax for the function body - <code>return []</code> should be <code>return fibonacci(n)</code></li>\n",
            "</ul>\n",
            "\n",
            "<p>Logical errors:</p>\n",
            "\n",
            "<ul>\n",
            "<li>The function is not returning anything, so the return statement is not necessary</li>\n",
            "<li>The function is not taking any arguments, so the function name should be <code>fibonacci(n)</code></li>\n",
            "</ul>\n",
            "\n",
            "<p>The corrected code should be:</p>\n",
            "\n",
            "<pre><code>def fibonacci(n):\n",
            "    if n &lt; 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "</code></pre>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 6 \u2014 Define Corrector Agent\n",
        "def correct_code(code, analysis):\n",
        "    prompt = f\"\"\"\n",
        "You are a Python code corrector.\n",
        "Here is the code with its analysis report:\n",
        "Code:\n",
        "{code}\n",
        "\n",
        "Analysis:\n",
        "{analysis}\n",
        "\n",
        "Provide the corrected version of the code, fully functional and properly formatted.\n",
        "\"\"\"\n",
        "    result = llm(prompt)[0][\"generated_text\"]\n",
        "    return result\n",
        "\n",
        "# Test Corrector\n",
        "corrected_code = correct_code(buggy_code, analysis_report)\n",
        "print(\"=== Corrected Code ===\")\n",
        "print(corrected_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ukHhxnQmPi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658794587,
          "user_tz": -330,
          "elapsed": 9763,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "3ed258ba-d77e-4bf9-c0b2-9169811e0361"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Corrected Code ===\n",
            "\n",
            "You are a Python code corrector.\n",
            "Here is the code with its analysis report:\n",
            "Code:\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "\n",
            "Analysis:\n",
            "\n",
            "You are a Python code analyzer.\n",
            "Analyze the following Python code and list all syntax and logical errors clearly:\n",
            "\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "<p>Syntax errors:</p>\n",
            "\n",
            "<ul>\n",
            "<li>Incorrect syntax for the function name - <code>fibonacci</code> should be <code>fibonacci(n)</code></li>\n",
            "<li>Incorrect syntax for the function arguments - <code>n</code> should be a number (not a string)</li>\n",
            "<li>Incorrect syntax for the function body - <code>return []</code> should be <code>return fibonacci(n)</code></li>\n",
            "</ul>\n",
            "\n",
            "<p>Logical errors:</p>\n",
            "\n",
            "<ul>\n",
            "<li>The function is not returning anything, so the return statement is not necessary</li>\n",
            "<li>The function is not taking any arguments, so the function name should be <code>fibonacci(n)</code></li>\n",
            "</ul>\n",
            "\n",
            "<p>The corrected code should be:</p>\n",
            "\n",
            "<pre><code>def fibonacci(n):\n",
            "    if n &lt; 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "</code></pre>\n",
            "\n",
            "Provide the corrected version of the code, fully functional and properly formatted.\n",
            "\n",
            "The corrected code is:\n",
            "\n",
            "<pre><code>def fibonacci(n):\n",
            "    if n &lt; 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "</code></pre>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 7 \u2014 Manager Agent (Workflow Orchestration)\n",
        "def manager_workflow(code):\n",
        "    print(\"Manager: Starting workflow...\\n\")\n",
        "\n",
        "    # Step 1: Analyze\n",
        "    analysis = analyze_code(code)\n",
        "    print(\"Manager: Analysis complete.\\n\", analysis, \"\\n\")\n",
        "\n",
        "    # Step 2: Correct\n",
        "    corrected = correct_code(code, analysis)\n",
        "    print(\"Manager: Code correction complete.\\n\", corrected, \"\\n\")\n",
        "\n",
        "    print(\"Manager: Workflow executed successfully.\")\n",
        "    return corrected\n",
        "\n",
        "# Run the complete CRU-AI workflow\n",
        "final_code = manager_workflow(buggy_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPCjDEcAQmRy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658812227,
          "user_tz": -330,
          "elapsed": 17633,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        },
        "outputId": "52a45fa6-478e-47be-e427-0d6d5c9e0252"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manager: Starting workflow...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manager: Analysis complete.\n",
            " \n",
            "You are a Python code analyzer.\n",
            "Analyze the following Python code and list all syntax and logical errors clearly:\n",
            "\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "<p>Syntax errors:</p>\n",
            "<ul>\n",
            "<li>The function name is not defined in the code.</li>\n",
            "<li>The function is not defined in the code.</li>\n",
            "<li>The function is defined twice in the code.</li>\n",
            "</ul>\n",
            "<p>Logical errors:</p>\n",
            "<ul>\n",
            "<li>The function is not defined in the code.</li>\n",
            "<li>The function is defined twice in the code.</li>\n",
            "</ul> \n",
            "\n",
            "Manager: Code correction complete.\n",
            " \n",
            "You are a Python code corrector.\n",
            "Here is the code with its analysis report:\n",
            "Code:\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "\n",
            "Analysis:\n",
            "\n",
            "You are a Python code analyzer.\n",
            "Analyze the following Python code and list all syntax and logical errors clearly:\n",
            "\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n < 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "\n",
            "<p>Syntax errors:</p>\n",
            "<ul>\n",
            "<li>The function name is not defined in the code.</li>\n",
            "<li>The function is not defined in the code.</li>\n",
            "<li>The function is defined twice in the code.</li>\n",
            "</ul>\n",
            "<p>Logical errors:</p>\n",
            "<ul>\n",
            "<li>The function is not defined in the code.</li>\n",
            "<li>The function is defined twice in the code.</li>\n",
            "</ul>\n",
            "\n",
            "Provide the corrected version of the code, fully functional and properly formatted.\n",
            "<pre><code>def fibonacci(n):\n",
            "    if n &lt; 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 0, 1\n",
            "    else:\n",
            "        fib = [0, 1]\n",
            "        for i in range(2, n):\n",
            "            fib.append(fib[i-1] + fib[i-2])\n",
            "        return fib\n",
            "</code></pre> \n",
            "\n",
            "Manager: Workflow executed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ij_Nj0LQmUJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1768658812230,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "Himanshu Singh",
            "userId": "14360045562030520660"
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}