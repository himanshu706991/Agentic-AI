{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements a multi-agent research and summarization system using LangGraph in a Colab environment.\n",
        "\n",
        "Objective:\n",
        "\n",
        "To design a workflow that processes user queries and routes them to the appropriate agent for reasoning, retrieval, or web research.\n",
        "\n",
        "The system consists of the following workflow:\n",
        "\n",
        "Router Agent: Determines the query intent and decides whether to invoke LLM reasoning, RAG retrieval from a dataset, or a Web Research agent.\n",
        "\n",
        "LLM Agent: Performs reasoning on queries that require generated knowledge.\n",
        "\n",
        "RAG Agent: Retrieves relevant information from a predefined dataset (dummy dataset included).\n",
        "\n",
        "Web Research Agent: Fetches up-to-date information from the web when needed.\n",
        "\n",
        "Summarization Agent: Synthesizes results from all agents into a well-structured final response, ready for PDF export.\n",
        "\n",
        "Purpose:\n",
        "This notebook demonstrates:\n",
        "\n",
        "The construction of a multi-agent workflow using LangGraph.\n",
        "\n",
        "Conditional routing and parallel agent execution.\n",
        "\n",
        "Visualization of the workflow with nodes and edges.\n",
        "\n",
        "Execution of queries at runtime with results integrated from multiple specialized agents.\n",
        "\n",
        "It serves as a foundation for advanced multi-agent systems and research summarization workflows in Python."
      ],
      "metadata": {
        "id": "YexN-genxJtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 1 — Install Dependencies (Colab Safe)\n",
        "!pip install -q --upgrade langgraph langchain langchain-groq faiss-cpu reportlab"
      ],
      "metadata": {
        "id": "lR_QwJ3mxF6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 2 — Set Groq API Key\n",
        "import os\n",
        "\n",
        "# Replace with your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "YwlLuwY0szCb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 3 — Imports\n",
        "from typing import TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_groq import ChatGroq\n"
      ],
      "metadata": {
        "id": "VL4wsDgms6QS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 4 — Define Shared Graph State\n",
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    route: Optional[str]\n",
        "    llm_result: Optional[str]\n",
        "    rag_result: Optional[str]\n",
        "    web_result: Optional[str]\n",
        "    final_answer: Optional[str]\n"
      ],
      "metadata": {
        "id": "O931-G00tA9y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 5 — Initialize Groq LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "N5igMYtgtDSQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 6 — Define Router Agent\n",
        "def router_agent(state: AgentState):\n",
        "    query = state[\"query\"].lower()\n",
        "\n",
        "    if \"document\" in query or \"internal\" in query or \"dataset\" in query:\n",
        "        route = \"rag\"\n",
        "    elif \"latest\" in query or \"news\" in query or \"web\" in query:\n",
        "        route = \"web\"\n",
        "    else:\n",
        "        route = \"llm\"\n",
        "\n",
        "    return {\"route\": route}\n"
      ],
      "metadata": {
        "id": "HExNRn1ZtDUp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 7 — Define LLM Reasoning Agent\n",
        "def llm_agent(state: AgentState):\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    response = llm.invoke(f\"\"\"\n",
        "You are a reasoning assistant.\n",
        "Answer the following query clearly and concisely:\n",
        "\n",
        "{query}\n",
        "\"\"\")\n",
        "\n",
        "    return {\"llm_result\": response.content}\n"
      ],
      "metadata": {
        "id": "pzrONMbMtDc5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 8 — Define RAG Agent (Dummy Knowledge Base)\n",
        "# Dummy knowledge base\n",
        "KNOWLEDGE_BASE = {\n",
        "    \"langgraph\": \"LangGraph is a framework for building multi-agent workflows using graph-based state machines.\",\n",
        "    \"rag\": \"RAG (Retrieval-Augmented Generation) enhances LLMs by retrieving relevant documents before generation.\",\n",
        "    \"multi agent\": \"Multi-agent systems consist of specialized agents collaborating to solve complex tasks.\"\n",
        "}\n",
        "\n",
        "def rag_agent(state: AgentState):\n",
        "    query = state[\"query\"].lower()\n",
        "\n",
        "    retrieved_text = \"No relevant internal data found.\"\n",
        "\n",
        "    for key, value in KNOWLEDGE_BASE.items():\n",
        "        if key in query:\n",
        "            retrieved_text = value\n",
        "            break\n",
        "\n",
        "    return {\"rag_result\": f\"[RAG Retrieval]\\n{retrieved_text}\"}\n"
      ],
      "metadata": {
        "id": "JIr9PfE9tTJX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 9 — Define Web Research Agent (Simulated)def web_agent(state: AgentState):\n",
        "def web_agent(state: AgentState):\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    return {\n",
        "        \"web_result\": f\"[Web Research]\\nSimulated web search results for: '{query}'.\\n(You can replace this with a real search API later.)\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "7PLovY19tVWx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 10 — Define Summarization Agent (Final Node)\n",
        "def summarizer_agent(state: AgentState):\n",
        "    parts = []\n",
        "\n",
        "    if state.get(\"llm_result\"):\n",
        "        parts.append(\"LLM Reasoning:\\n\" + state[\"llm_result\"])\n",
        "    if state.get(\"rag_result\"):\n",
        "        parts.append(\"RAG Retrieval:\\n\" + state[\"rag_result\"])\n",
        "    if state.get(\"web_result\"):\n",
        "        parts.append(\"Web Research:\\n\" + state[\"web_result\"])\n",
        "\n",
        "    final_answer = \"\\n\\n\".join(parts)\n",
        "\n",
        "    return {\"final_answer\": final_answer}\n"
      ],
      "metadata": {
        "id": "GUS54rB4tVZW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 11 — Build the LangGraph (Your Exact Diagram)\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Nodes\n",
        "workflow.add_node(\"start\", lambda state: state)\n",
        "workflow.add_node(\"router\", router_agent)\n",
        "workflow.add_node(\"llm\", llm_agent)\n",
        "workflow.add_node(\"rag\", rag_agent)\n",
        "workflow.add_node(\"web\", web_agent)\n",
        "workflow.add_node(\"summary\", summarizer_agent)\n",
        "\n",
        "# Edges\n",
        "workflow.add_edge(\"start\", \"router\")\n",
        "\n",
        "# Router branching\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda state: state[\"route\"],\n",
        "    {\n",
        "        \"llm\": \"llm\",\n",
        "        \"rag\": \"rag\",\n",
        "        \"web\": \"web\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Parallel paths → Summarization\n",
        "workflow.add_edge(\"llm\", \"summary\")\n",
        "workflow.add_edge(\"rag\", \"summary\")\n",
        "workflow.add_edge(\"web\", \"summary\")\n",
        "\n",
        "# End\n",
        "workflow.add_edge(\"summary\", END)\n",
        "\n",
        "# Entry point\n",
        "workflow.set_entry_point(\"start\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85qVIeIgtVcR",
        "outputId": "64c7b940-6d9b-4147-8e75-120c4cc1eb65"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7eb1dec69ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 12 — Compile Graph\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "I-rlASf5tVfI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 13 — Visualize the Graph (Show Instructor)\n",
        "print(\"\\n===== LANGGRAPH STRUCTURE =====\\n\")\n",
        "print(app.get_graph())\n",
        "\n",
        "display(app.get_graph().draw_mermaid())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "PukmX48KtVhV",
        "outputId": "93187f01-f1ea-4332-e019-15f976c979d3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== LANGGRAPH STRUCTURE =====\n",
            "\n",
            "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=RunnableCallable(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'start': Node(id='start', name='start', data=start(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'router': Node(id='router', name='router', data=router(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'llm': Node(id='llm', name='llm', data=llm(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'rag': Node(id='rag', name='rag', data=rag(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'web': Node(id='web', name='web', data=web(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'summary': Node(id='summary', name='summary', data=summary(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=None, metadata=None)}, edges=[Edge(source='__start__', target='start', data=None, conditional=False), Edge(source='llm', target='summary', data=None, conditional=False), Edge(source='rag', target='summary', data=None, conditional=False), Edge(source='router', target='llm', data=None, conditional=True), Edge(source='router', target='rag', data=None, conditional=True), Edge(source='router', target='web', data=None, conditional=True), Edge(source='start', target='router', data=None, conditional=False), Edge(source='web', target='summary', data=None, conditional=False), Edge(source='summary', target='__end__', data=None, conditional=False)])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'---\\nconfig:\\n  flowchart:\\n    curve: linear\\n---\\ngraph TD;\\n\\t__start__([<p>__start__</p>]):::first\\n\\tstart(start)\\n\\trouter(router)\\n\\tllm(llm)\\n\\trag(rag)\\n\\tweb(web)\\n\\tsummary(summary)\\n\\t__end__([<p>__end__</p>]):::last\\n\\t__start__ --> start;\\n\\tllm --> summary;\\n\\trag --> summary;\\n\\trouter -.-> llm;\\n\\trouter -.-> rag;\\n\\trouter -.-> web;\\n\\tstart --> router;\\n\\tweb --> summary;\\n\\tsummary --> __end__;\\n\\tclassDef default fill:#f2f0ff,line-height:1.2\\n\\tclassDef first fill-opacity:0\\n\\tclassDef last fill:#bfb6fc\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 14 — Runtime Input (Multiple Testing)\n",
        "user_query = input(\"Enter your question: \")\n",
        "\n",
        "result = app.invoke({\n",
        "    \"query\": user_query,\n",
        "    \"route\": None,\n",
        "    \"llm_result\": None,\n",
        "    \"rag_result\": None,\n",
        "    \"web_result\": None,\n",
        "    \"final_answer\": None,\n",
        "})\n",
        "\n",
        "print(\"\\n========== FINAL ANSWER ==========\\n\")\n",
        "print(result[\"final_answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fyhaja4t321",
        "outputId": "71ecf664-7543-4b3e-9e99-ebdd45802ca9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: Explain multi-agent systems in AI\n",
            "\n",
            "========== FINAL ANSWER ==========\n",
            "\n",
            "LLM Reasoning:\n",
            "**Multi-Agent Systems (MAS) in AI:**\n",
            "\n",
            "A Multi-Agent System (MAS) is a type of artificial intelligence (AI) system that consists of multiple autonomous agents that interact with each other and their environment to achieve common or conflicting goals.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "1. **Autonomy**: Each agent operates independently, making decisions based on its own goals and knowledge.\n",
            "2. **Interdependence**: Agents interact with each other and their environment to achieve their goals.\n",
            "3. **Distributed Problem-Solving**: MAS can solve complex problems that are difficult or impossible for a single agent to solve.\n",
            "\n",
            "**Components of a MAS:**\n",
            "\n",
            "1. **Agents**: Individual entities that perceive their environment, reason, and act to achieve their goals.\n",
            "2. **Environment**: The external world that agents interact with.\n",
            "3. **Communication**: Agents can exchange information and coordinate their actions.\n",
            "\n",
            "**Types of MAS:**\n",
            "\n",
            "1. **Single-Goal MAS**: Agents work together to achieve a single goal.\n",
            "2. **Multi-Goal MAS**: Agents have conflicting goals and may negotiate or compete to achieve their objectives.\n",
            "3. **Hybrid MAS**: A combination of single-goal and multi-goal MAS.\n",
            "\n",
            "**Applications of MAS:**\n",
            "\n",
            "1. **Robotics**: Autonomous robots that interact with each other and their environment.\n",
            "2. **Intelligent Transportation Systems**: Agents coordinate traffic flow and optimize routes.\n",
            "3. **E-commerce**: Agents negotiate prices and optimize supply chains.\n",
            "4. **Social Networks**: Agents interact and influence each other's behavior.\n",
            "\n",
            "**Benefits of MAS:**\n",
            "\n",
            "1. **Scalability**: MAS can handle complex problems that are difficult for a single agent to solve.\n",
            "2. **Flexibility**: Agents can adapt to changing environments and goals.\n",
            "3. **Robustness**: MAS can recover from failures and continue operating.\n",
            "\n",
            "**Challenges of MAS:**\n",
            "\n",
            "1. **Complexity**: Managing multiple agents and their interactions can be difficult.\n",
            "2. **Communication**: Ensuring effective communication between agents is crucial.\n",
            "3. **Trust**: Establishing trust between agents is essential for successful collaboration.\n",
            "\n",
            "In summary, Multi-Agent Systems are a powerful tool for solving complex problems in AI, enabling autonomous agents to interact and collaborate to achieve their goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 14 — Runtime Input (Multiple Testing)\n",
        "user_query = input(\"Enter your question: \")\n",
        "\n",
        "result = app.invoke({\n",
        "    \"query\": user_query,\n",
        "    \"route\": None,\n",
        "    \"llm_result\": None,\n",
        "    \"rag_result\": None,\n",
        "    \"web_result\": None,\n",
        "    \"final_answer\": None,\n",
        "})\n",
        "\n",
        "print(\"\\n========== FINAL ANSWER ==========\\n\")\n",
        "print(result[\"final_answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ1tniG-wlkN",
        "outputId": "e34a5079-3568-4a85-f39c-e0a331413b79"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: What does the internal document say about LangGraph?\n",
            "\n",
            "========== FINAL ANSWER ==========\n",
            "\n",
            "RAG Retrieval:\n",
            "[RAG Retrieval]\n",
            "LangGraph is a framework for building multi-agent workflows using graph-based state machines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 14 — Runtime Input (Multiple Testing)\n",
        "user_query = input(\"Enter your question: \")\n",
        "\n",
        "result = app.invoke({\n",
        "    \"query\": user_query,\n",
        "    \"route\": None,\n",
        "    \"llm_result\": None,\n",
        "    \"rag_result\": None,\n",
        "    \"web_result\": None,\n",
        "    \"final_answer\": None,\n",
        "})\n",
        "\n",
        "print(\"\\n========== FINAL ANSWER ==========\\n\")\n",
        "print(result[\"final_answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTc0H25uwtYS",
        "outputId": "9be4ccce-f8a9-4806-ddc9-3e4f6555bd1a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: What are the latest AI trends in 2025?\n",
            "\n",
            "========== FINAL ANSWER ==========\n",
            "\n",
            "Web Research:\n",
            "[Web Research]\n",
            "Simulated web search results for: 'What are the latest AI trends in 2025?'.\n",
            "(You can replace this with a real search API later.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "graph = app.get_graph()\n",
        "\n",
        "print(\"===== TEXT STRUCTURE =====\")\n",
        "print(graph)\n",
        "\n",
        "print(\"\\n===== VISUAL LANGGRAPH DIAGRAM =====\")\n",
        "display(graph.draw_mermaid())\n"
      ],
      "metadata": {
        "id": "ax6CML54uWVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    route: Optional[str]\n",
        "    llm_result: Optional[str]\n",
        "    rag_result: Optional[str]\n",
        "    web_result: Optional[str]\n",
        "    final_answer: Optional[str]\n"
      ],
      "metadata": {
        "id": "Xse6CKPuu2pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy nodes (logic doesn't matter for the diagram)\n",
        "def start_node(state):\n",
        "    return state\n",
        "\n",
        "def router_agent(state):\n",
        "    # hard routing logic just for structure\n",
        "    return {\"route\": \"llm\"}\n",
        "\n",
        "def llm_agent(state):\n",
        "    return {\"llm_result\": \"LLM Output\"}\n",
        "\n",
        "def rag_agent(state):\n",
        "    return {\"rag_result\": \"RAG Output\"}\n",
        "\n",
        "def web_agent(state):\n",
        "    return {\"web_result\": \"Web Output\"}\n",
        "\n",
        "def summarizer_agent(state):\n",
        "    return {\"final_answer\": \"Final Answer\"}\n"
      ],
      "metadata": {
        "id": "XGw0j1Acu2sD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes (VERTICES)\n",
        "workflow.add_node(\"start\", start_node)\n",
        "workflow.add_node(\"router\", router_agent)\n",
        "workflow.add_node(\"llm\", llm_agent)\n",
        "workflow.add_node(\"rag\", rag_agent)\n",
        "workflow.add_node(\"web\", web_agent)\n",
        "workflow.add_node(\"summary\", summarizer_agent)\n",
        "\n",
        "# Define edges (CONNECTIONS)\n",
        "workflow.add_edge(\"start\", \"router\")\n",
        "\n",
        "# Router → three parallel branches\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda state: state[\"route\"],\n",
        "    {\n",
        "        \"llm\": \"llm\",\n",
        "        \"rag\": \"rag\",\n",
        "        \"web\": \"web\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# All three → summarizer\n",
        "workflow.add_edge(\"llm\", \"summary\")\n",
        "workflow.add_edge(\"rag\", \"summary\")\n",
        "workflow.add_edge(\"web\", \"summary\")\n",
        "\n",
        "# Summarizer → END\n",
        "workflow.add_edge(\"summary\", END)\n",
        "\n",
        "# Entry point\n",
        "workflow.set_entry_point(\"start\")\n",
        "\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "s1g7QQAju6cf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "mermaid = app.get_graph().draw_mermaid()\n",
        "\n",
        "HTML(f\"\"\"\n",
        "<div class=\"mermaid\">\n",
        "{mermaid}\n",
        "</div>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js\"></script>\n",
        "<script>mermaid.initialize({{ startOnLoad: true }});</script>\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "7vxKM8FIu8j1",
        "outputId": "e4be6f3e-5cd7-4fe2-8332-b0bb2c94a032"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div class=\"mermaid\">\n",
              "---\n",
              "config:\n",
              "  flowchart:\n",
              "    curve: linear\n",
              "---\n",
              "graph TD;\n",
              "\t__start__([<p>__start__</p>]):::first\n",
              "\tstart(start)\n",
              "\trouter(router)\n",
              "\tllm(llm)\n",
              "\trag(rag)\n",
              "\tweb(web)\n",
              "\tsummary(summary)\n",
              "\t__end__([<p>__end__</p>]):::last\n",
              "\t__start__ --> start;\n",
              "\tllm --> summary;\n",
              "\trag --> summary;\n",
              "\trouter -.-> llm;\n",
              "\trouter -.-> rag;\n",
              "\trouter -.-> web;\n",
              "\tstart --> router;\n",
              "\tweb --> summary;\n",
              "\tsummary --> __end__;\n",
              "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
              "\tclassDef first fill-opacity:0\n",
              "\tclassDef last fill:#bfb6fc\n",
              "\n",
              "</div>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js\"></script>\n",
              "<script>mermaid.initialize({ startOnLoad: true });</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}